---
title:
layout: page
comments: false
---

This is the academic website of [Thilo Stadelmann](https://www.zhaw.ch/en/about-us/person/stdm/), professor of **artificial intelligence** and **machine learning** at the [ZHAW](https://www.zhaw.ch/en/university/) [School of Engineering](https://www.zhaw.ch/en/engineering) and holder of the chair of Engineering-Information, director of the [Centre for Artificial Intelligence](https://www.zhaw.ch/en/engineering/institutes-centres/cai/) and head of its [Machine Perception and Cognition Group](https://www.zhaw.ch/en/engineering/institutes-centres/cai/machine-perception-and-cognition-group/). He is also (co-)founder and board member of [AlpineAI AG](https://alpineai.swiss/) and the [ZHAW Datalab](https://www.zhaw.ch/datalab), pioneered [several other organizations](https://www.linkedin.com/in/thilo-stadelmann/), frequently gives [keynote talks](https://premium-speakers.com/en/speaker-presenter/thilo-stadelmann/), and received several [awards](https://www.zhaw.ch/en/about-us/person/stdm/) for his teaching, research, and ecosystem engagement. Views expressed are his own.


### TOC
1. [Biography](#bio)
2. [The Machine Perception and Cognition group](#group)
3. [Research examples](#work)
4. [Collaborations](#collaborations)
5. [Publications](#publications)


<a name="bio"></a>
## Biography

<img src="http://stdm.github.io/images/thilo-2024.jpg"/>

Thilo studied computer science in Giessen and Marburg and received the Doctor of Science degree from [Marburg University](https://www.informatik.uni-marburg.de/~stadelmann/), Germany, in 2010, where he worked on multimedia analysis and voice recognition. Thilo held engineering and leadership roles in the automotive industry for several years prior to the appointment at the ZHAW. His current research interests revolve around robust representation learning in deep neural networks for pattern recognition problems; how to learn structured and actionable representations for world models; and societal effects of AI. The group and research is introduced in more detail [below](#group).

A personal note: I like kitesurfing, enjoy playing music on stringed instruments (guitars, bass), and am a follower of <a href="https://odb.org/">Jesus Christ</a>. If this makes you curious, send me an email with a meeting request (subject "30 minutes on faith"), I am happy to explain. I try living by the following values (my closer colleagues know I am not there yet): excellence; wisdom; honor all people; mercy for failure; and courage.


<a name="group"></a>
## The Machine Perception and Cognition group

[<img alt="The ZHAW Centre for AI members as of March 2024" src="http://stdm.github.io/images/CAI-2024.jpg"/>](http://stdm.github.io/images/CAI-2024.jpg)

The [Machine Perception and Cognition Group](https://www.zhaw.ch/en/engineering/institutes-centres/cai/machine-perception-and-cognition-group/) performs project-based research in **representation learning** for **pattern recognition**, working on a wide variety of tasks on image, audio or generally "signal" data. As a group, we focus on **deep learning** methodology, inspired by biological learning. Each task that we study has its own learning target (e.g., detection, classification, clustering, segmentation, novelty detection, control) and use case (e.g., **predictive maintenance**, **speaker diarization**  for multimedia indexing, **document analysis**, **optical music recognition**, **computer vision** for industrial quality control, **automated machine learning**, **deep reinforcement learning** for automated game play or building control), which in turn sheds light on different aspects of the learning process. We also engage in interdisciplinary work on the ethical and societal aspects of AI.

The group has very diverse backgrounds, which helps us complement each other's skills.

<details>
<summary><b>Staff and students</b></summary>  
<ul>
    <li><a href="https://de.wikipedia.org/wiki/Thilo_Stadelmann">Prof. Dr. Thilo Stadelmann</a>, group lead: Diplom (THM) & PhD (U. Marburg) in computer science</li>
    <li><a href="https://scholar.google.com/citations?user=XqaePW0AAAAJ">Dr. Ahmed Abdulkadir</a>, senior researcher: B.Sc. systems engineering (NTB Buchs), BSc & MSc Life Sciences (EPFL), PhD computer engineering (University of Freiburg / Germany), PostDoc University Hospital Bern / University of Pennsylvania / Lausanne University Hospital</li>
    <li><a href="https://www.linkedin.com/in/hella-bolck-783a6526">Dr. Hella Bolck</a>, coordinator for complex projects: M.Sc. biochemistry and molecular biology (U Jena), PhD cancer biology (U Zurich), postdoc & senior scientist (USZ)</li>
    <li><a href="https://tuggeluk.github.io/">Lukas Tuggener</a>, PhD student: B.Sc. industrial engineering (ZHAW), M.Sc. statistics (ETH), doctorate in conjunction with <a href="http://people.idsia.ch/~juergen/">Juergen Schmidhuber</a> of the University of Lugano / Switzerland</li>
    <li><a href="https://www.linkedin.com/in/waqar-ali-92468910b/">Waqar Ali</a>, PhD student: M.Sc. (CU Islamabad) in computer science, doctorate in conjunction with <a href="https://www.dsi.unive.it/~pelillo/">Marcello Pelillo</a> of the University of Venice / Italy</li>
    <li><a href="https://www.linkedin.com/in/peng520/">Peng Yan</a>, PhD student: B.Sc. measuring & control technology (Jianghan U.) & M.Sc. control engineering (Xiamen U.), M.Sc. data science (UZH), doctorate in conjunction with <a href="https://www.ini.uzh.ch/en/research/groups/grewe.html">Benjamin F. Grewe</a> of the University of Zurich / Switzerland</li>
    <li><a href="https://www.linkedin.com/in/pascal-sager-3b7403168">Pascal Sager</a>, PhD student: B.Sc. & M.Sc. computer science (ZHAW), doctorate in conjunction with <a href="https://www.ini.uzh.ch/en/research/groups/grewe.html">Benjamin F. Grewe</a> of the University of Zurich / Switzerland</li>
    <li><a href="https://www.linkedin.com/in/benjamin-meyer-b87077151">Benjamin Meyer</a>, PhD student: B.Sc. information technology (FHNW), M.Sc. computer science (U Basel), doctorate in conjunction with <a href="https://www.ini.uzh.ch/en/research/groups/grewe.html">Benjamin F. Grewe</a> of the University of Zurich / Switzerland</li>
    <li><a href="https://www.linkedin.com/in/livia-l%C3%BCscher-72aaaa139/">Livia Luescher</a>, M.Sc. student: B.Sc. business administration with honors (HWZ Zurich)</li>
    <li><a href="https://www.linkedin.com/in/adrian-th%C3%BCr-01976b160/">Adrian Thuer</a>, M.Sc. student: B.Sc. computer science (ZHAW)</li>
    <li><a href="https://www.linkedin.com/in/elia-untern%C3%A4hrer-201593255/">Elia Unternährer</a>, M.Sc. student: B.Sc. business information technology (ZHAW)</li>
    <li><a href="https://www.linkedin.com/in/jakub-hanush/">Jakub Hanuska</a>, M.Sc. student: B.Sc. open informatics (Mendel University of Brno)</li>
    <li><a href="https://www.linkedin.com/in/rebekka-von-wartburg-3b807b298/">Rebekka von Wartburg</a>, M.Sc. student: B.Sc. computer science (ZHAW)</li>
</ul>
</details>  

<details>
<summary><b>Alumni</b></summary>
<ul>
  <li> <a href="https://www.linkedin.com/in/raphael-emberger-206015bb">Raphael Emberger</a>, research assistant 2012-2024, M.Sc. and B.Sc. computer science (ZHAW) <br>&rarr; Deep Learning Engineer @ Rheinmetall Air Defence</li>
  <li> <a href="https://www.zhaw.ch/en/about-us/person/ayfe/">Erdal Ayfer</a>, intern 2023-2024, B.Sc. student computer science(ZHAW)</li>
  <li> <a href="https://www.linkedin.com/in/sydney-nguyen-117987180/">Sydney M. Nguyen</a>, M.Sc. student 2022-2024, B.Sc. in computer science (ZHAW) <br>&rarr; Solution Engineer Data & AI @ mesoneer</li>
  <li> <a href="https://www.linkedin.com/in/sebastian-salzmann-8214b911b">Sebastian Salzmann</a>, M.Sc. student 2021-2024, B.Sc. biology (ETH) & M.Sc. molecular health sciences (ETH) <br>&rarr; Scientific IT @ EAWAG</li>
  <li> <a href="https://www.linkedin.com/in/paul-l-821892247/">Paul Luley</a>, research assistent 2022-2023, B.Sc. biomedical engineering (Technikum Vienna) <br>&rarr; Data Science Researcher @ Julius Bär</li>
  <li> <a href="https://scholar.google.com/citations?user=ZU1fTMYAAAAJ&hl=en">Dr. Ricardo Chavarriaga</a>, B.Sc. electronics engineering (Pontificia Universidad Javeriana, Columbia), graduate school in computer/communication/information science (EPFL), PhD neuroscience (EPFL), Postdoc neuroscience/brain-computer interfaces (EPFL & IDIAP), senior researcher 2019-2023 <br>&rarr; Head of Responsible AI Innovation Group @ ZHAW CAI</li>
  <li> <a href="https://www.zhaw.ch/en/about-us/person/amir/">Mohammadreza Amirian</a>, B.Sc. (U. Shiraz) & M.Sc. (U. Ulm) in electrical engineering, PhD 2017-2023 in conjunction with [Friedhelm Schwenker</a>https://www.uni-ulm.de/in/neuroinformatik/institut/hidden/f-schwenker/) of Ulm University / Germany <br>&rarr; Deep learning and computer vision researcher @ HES-SO Valais-Wallis</li>
  <li> <a href="https://www.linkedin.com/in/adhiraj-ghosh/">Adhiraj Ghosh</a>, B.Tech. (Manipal Institute of Technology), research intern 2021/22 (ZHAW) <br>&rarr; M.Sc. student @ Tübingen University</li>
  <li> <a href="https://www.zhaw.ch/en/about-us/person/lehl/">Claude Olivier Lehmann</a>, M.Sc. and B.Sc. (ZHAW) <br>&rarr; PhD student with Prof. Kurt Stockinger @ ZHAW InIT</li>
  <li> <a href="http://www.fp-schilling.de">Dr. Frank-Peter Schilling</a> Diplom & PhD (U. Heidelberg) in physics, PostDoc at CERN <br>&rarr; Head of Intelligent Vision Systems Group @ ZHAW CAI</li>
  <li> <a href="https://scholar.google.de/citations?user=5cpeK3MAAAAJ&hl=en">Dr. Javier Montoya</a>, B.Sc. computer engineering (UCSP, Arequipa, Peru), M.Sc. computer science (Unicamp, Sao Paulo, Brazil), M.Sc. computer science (ENSIMAG, Grenoble, France), PhD computer vision and machine learning (ETHZ) <br>&rarr; Senior lecturer of computer science @ Lucerne University of Applied Sciences</li>
  <li> Stefan Huschauer: B.Sc. computer science (ETH & ZHAW), M.Sc. (ZHAW) <br>&rarr; Noimos, an AXA insuretech company</li>
  <li> <a href="https://ba-pub.engineering.zhaw.ch/WebPublication/Flyer.pdf?version=Bachelorarbeit2018&code=BA18_wyrs_3&language=de">Daniel Neururer</a>, B.Sc. in systems engineering (ZHAW), M.Sc. 2020 (ZHAW) <br>&rarr; Software Engineer @ mcs software AG</li>
  <li> <a href="https://github.com/TheRevanchist">Dr. Ismail Elezi</a>, B.Sc. (U. Pristina), M.Sc. (Ca'Foscari) & PhD (Ca'Foscari & ZHAW, July 2020) in computer science <br>&rarr; Senior Research Scientist / Tech Lead @ Huawei Noah’s Ark</li>
  <li> <a href="https://www.linkedin.com/in/yvan-satyawan">Yvan Satyawan</a>, B.Sc. computer science (U. Freiburg, Germany) <br>&rarr; Founder @ stealth-mode start-up</li>
  <li> <a href="https://dblp.uni-trier.de/pers/hd/r/Rombach:Katharina">Katharina Rombach</a>, B.Sc. & M.Sc. (ETH Zurich; admitted to EDIC and ERDS doctoral schools at EPFL) <br>&rarr; PhD student with Prof. Olga Fink @ EPFL</li>
  <li> <a href="https://www.linkedin.com/in/reza-kakooee/">Reza Kakooee</a>, M.Sc. (U. Mashhad) &rarr; PhD student with Prof. Marc Pouly @ Lucerne University of Applied Sciences</li>
  <li> <a href="https://www.linkedin.com/in/benjamin-meier-61ab078b/">Benjamin Bruno Meier</a>, M.Sc. (ZHAW; Hirschmann scholarship holder & Dr. Waldemar Jucker laureate) <br>&rarr; Software Engineer @ Argus Data Insights Schweiz AG</li>
  <li> <a href="https://www.linkedin.com/in/gabriel-eyyi/">Gabriel Eyyi</a>, M.Sc. (ZHAW) <br>&rarr; Software Engineer / Machine Learning Engineer @ dizmo AG</li>
  <li> <a href="https://www.linkedin.com/in/thierrymusy/">Thierry Musy</a>, B.Sc. (ZHAW) <br>&rarr; Partner / Senior Data Scientist @ Foursight Digital AG</li>
  <li> <a href="https://www.linkedin.com/in/janstampfli/">Jan Stampfli</a>, B.Sc. (ZHAW) <br>&rarr; Big Data Engineer @ Migros-Genossenschafts-Bund</li>
</ul>
</details>

 
<a name="work"></a>
## Research examples

<img alt="Neural network architecture to detect anomalies in injection molding processes." src="http://stdm.github.io/images/sds2024-architecture.jpg"/>

<a name="robust"></a>
<details>
<summary><b>Robust and practical deep learning</b></summary>

<img alt="Examples of automatic segmentation" src="http://stdm.github.io/images/article_segmentation.jpg"/>

<p>Deep learning has long reached the <a href="https://stdm.github.io/downloads/papers/ANNPR_2018d.pdf">point of practical applicability</a> in solving day-to-day tasks in many non-AI businesses, for instance manufacturing SMEs. Specific challenges arise and are tackled in our <a href="http://stdm.github.io/downloads/papers/ADS_2019_DeepLearning.pdf">applied research projects</a>, ranging from data quality and quantity issues to higher requirements on robustness and resilience of the models. For instance, segmenting newspaper pages into articles that semantically belong together is a necessary prerequisite for article-based information retrieval on print media collections like e.g. archives and libraries. It is challenging due to vastly differing layouts of papers, various content types and different languages, but commercially very relevant for e.g. media monitoring.</p>

<img alt="Newspaper article segmentation architecture" src="http://stdm.github.io/images/fcnn_architecture.jpg"/>

<p>Here, we have developed a <a href="http://stdm.github.io/downloads/papers/ICDAR_2017.pdf">semantic segmentation approach</a> based on the visual appearance of each page. We apply a fully convolutional neural network (FCN) that we train in an end-to-end fashion to transform the input image into a segmentation mask in one pass. We show experimentally that the FCN performs very well: it outperforms a deep learning-based commercial solution by a large margin in terms of segmentation quality while in addition being computationally two orders of magnitude more efficient. The whole system is trained with only 5,500 images of which less than 500 are fully labeled.</p>

<img alt="Detecting adversarial examples using local spatial entropy on feature response maps" src="http://stdm.github.io/images/adversarial_detection.jpg"/>

<p>At the same time, the existence of adversarial attacks on convolutional neural networks (CNN) questions the fitness of such models for serious applications. Such attacks manipulate an input image such that misclassification is evoked while still looking normal to a human observer - they are thus not easily detectable. In a different context, backpropagated activations of CNN hidden layers - "feature responses" to a given input - have been helpful to visualize for a human "debugger" what the CNN "looks at" while computing its output. We have proposed a novel <a href="http://stdm.github.io/downloads/papers/ANNPR_2018c.pdf">detection method for adversarial examples</a> to prevent attacks. We do so by tracking adversarial perturbations in feature responses, allowing for automatic detection using average local spatial entropy. The method does not alter the original network architecture and is fully human-interpretable. Experiments confirm the validity of our approach for state-of-the-art attacks on large-scale models trained on ImageNet.</p>

<p>As a final example, the prediction of product quality in an industrial plastic injection molding process (plus the needed process parameter adjustments to return to a non-anomalous process) can in principle be predicted from the evolution of the pressure within the cavity/tool. The problem is that the process is highly susceptible to little changes in the environmental conditions: The pressure curves look vastly different if only the sun shines on the machine over noon, for example. Hence, building a robust deep model to predict anomalies (and hopefully machine parameters) is a challenge of sucessful transfer learning. A first approach that works well for anomaly detection in this setup has been <a href="https://stdm.github.io/downloads/papers/SDS_2024c.pdf">published</a> based on VAE methods.</p>

<h4>Selected references</h4>
<ul>
  <li> Yan, P., Abdulkadir, A., Luley, P. P., Rosenthal, M., Schatte, G. A., Grewe, B. F., and Stadelmann, T. (2024). <a href="https://doi.org/10.1109/ACCESS.2023.3349132">A comprehensive survey of deep transfer learning for anomaly detection in industrial time series: Methods, applications, and directions</a>. IEEE Access.</li>

  <li> Stadelmann, T., Amirian, M., Arabaci, I., Arnold, M., Duivesteijn, G.F., Elezi, I., Geiger, M., Lörwald, S., Meier, B.B., Rombach, K. and Tuggener, L., 2018, September. <a href="https://stdm.github.io/downloads/papers/ANNPR_2018d.pdf">Deep Learning in the Wild</a>. In IAPR Workshop on Artificial Neural Networks in Pattern Recognition (pp. 17-38). Springer, Cham.</li>

  <li> Stadelmann, T., Tolkachev, V., Sick, B., Stampfli, J. and Dürr, O., 2019. <a href="https://stdm.github.io/downloads/papers/ADS_2019_DeepLearning.pdf">Beyond ImageNet - deep learning in industrial practice</a>. Applied Data Science-Lessons Learned for the Data-Driven Business. Springer.</li>
</ul>
</details>


<a name="general"></a>
<details>
<summary><b>Representation learning for next-level AI</b></summary>

<img alt="Illustration of Kolmogorov complexity: Perception and efficient learning are possible by reducing the flood of sensory signals produced by the environment to an underlying low-complexity description" src="http://stdm.github.io/images/kolmogorov.jpg"/>
    
<p>Deep learning has propelled the surge in AI in the last decade and will continue to find new applications and improvements. However, it is <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/interdisziplinaere-diskussionsrunde-am-cai-kolloquium-eroertert-was-intelligenz-ist-und-wie-man-die-ki-der-gegenwart-voranbringen-kann/">forseeable</a> that the methodology in itself will not produce higher-level cognition. Inspiration comes from neuroscientific research on understanding brain functionality. Here, we find the principle of self-organizing net fragments to be the inductive bias that fits models (developed brains) to the natural environment. We seek ways of implementing related ideas into deep learning frameworks to increas the generability and robustness of the approaches, which for example means to move away from purely error-driven learning by backgpropagation.</p>
    
<p>A current theme that makes the above arguments more tangible is how to learn actionable representations in world models that lead to representations structured in a way that allow desirable properties from interpretability to planning. Such structuring seems possible if models are not trained to just predict future values, but take intent (actions) into account to learn cause and effect, leading to a form of common sense.</p>
    
<h4>Selected references</h4>
<ul>
  <li>von der Malsburg, C., Grewe, B. F., and Stadelmann, T. (2022, September). <a href="https://stdm.github.io/downloads/papers/KogWis_2022.pdf">Making sense of the natural environment</a>. In The Biannual Conference of the German Cognitive Science Society (KogWis).</li>
  <li>von der Malsburg, C., Stadelmann, T., and Grewe, B. F., 2022. <a href="https://arxiv.org/abs/2205.00002">A Theory of Natural Intelligence</a>. arXiv preprint, arXiv:2205.00002.</li>
</ul>
</details>


<a name="trust"></a>
<details>
<summary><b>AI and society</b></summary>

<img alt="t-SNE visualization of the embedding space created by two face recognition models, coloured by ethnicity and gender" src="http://stdm.github.io/images/face-bias.jpg"/>

<p>How a powerful technology like artificial intelligence engages with the world around us and impacts our societies must concern us as engineers (to assess <a href="https://stdm.github.io/Risk/">risk</a>, provide <a href="https://stdm.github.io/Hope/">hope</a>, and <a href="https://stdm.github.io/AI-sports-humanism/">tell better stories</a> apart from dystopias). Assessing the impact of the technology on society is a first step to shape AI for good. In this direction, we for example <a href="https://link.springer.com/article/10.1007/s43681-021-00108-6">analyzed</a> how the effect of bias in face recognition systems can be quantified and mitigated. As our study shows, AI systems are very different from us humans: while for humans, conceiling information from us on sensitive attributes keeps us more fair / less biased, doing the same thing for a machine learning system - blinding it to attributes concerning e.g. gender or skin colour - does not result in less bias. Thus, bias does not equal awareness.</p>

<p>We also follow this thread of trustworthiness through projects on AI <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/3-neue-forschungsprojekte-zielen-auf-den-einsatz-vertrauenswuerdiger-ki/">verification and certification</a> as well as collaborations with colleagues from the humanities in projects and committees. The goal is to find better narratives for a hope-filled future with AI.</p>

<h4>Selected references</h4>
<ul>
    <li>Segessenmann, J., Stadelmann, T., Davison, A., and Dürr, O. (2023). <a href="https://link.springer.com/article/10.1007/s43681-023-00408-z">Assessing deep learning: a work program for the humanities in the age of artificial intelligence</a>. AI and Ethics, 1-32.</li>
    <li>Wehrli, S., Hertweck, C., Amirian, M., Glüge, S., and Stadelmann, T., 2021. <a href="https://link.springer.com/article/10.1007/s43681-021-00108-6">Bias, awareness and ignorance in deep-learning-based face recognition</a>. AI and Ethics, DOI 10.1007/s43681-021-00108-6, Springer, October 27, 2021.</li>
    <li>Glüge, S., Amirian, M., Flumini, D., and Stadelmann, T., 2020. <a href="https://stdm.github.io/downloads/papers/ANNPR_2020.pdf">How (Not) to Measure Bias in Face Recognition Networks</a>. In Proceedings of the 9th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (ANNPR'20), Springer, LNAI, Winterthur, Switzerland, September 02-04, 2020.</li>
</ul>
</details>


<a name="industrial"></a>
<details>
<summary><b>Industrial and medical computer vision</b></summary>

<img alt="Semantic segmentation pipeline to detect food waste" src="http://stdm.github.io/images/foodwaste.jpg"/>

<p>A rich source for open research questions in deep-learning-based pattern recognition is found in various industrial processes like engineering and production. For example, we developed methods to reliably classify and quantify <a href="https://www.zhaw.ch/en/engineering/about-us/news/news/event-news/tackling-food-waste-with-artificial-intelligence/">food waste</a> in large kitches through new semantic segmentation pipeline and worked a lot on automatic quality control. Other work in this area is going address the problem of <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/zhaw-and-kistler-team-up-to-evaluate-the-possibilities-of-deep-transfer-learning-for-controlling-injection-molding-processes/">transferability</a> of learnt knowledge from one tool to the next. As in industrial settings labelled data is usually scarce, a particular focus of our work is to make approaches more sample (or label) efficient than usual benchmark-beating models from the literature.</p>

<img alt="Vertebrae detection by deep learning model trained with unsupervised domain adaptation" src="http://stdm.github.io/images/vertebrae.jpg"/>

<p>Similary, health applications of deep learning are a major topic in the group. For example, in a collaboration with the AI and Data Science CoE of the Kantonsspital Aarau, we have <a href="https://www.mdpi.com/2313-433X/8/8/222">developed a novel approach</a> to reliably identify vertebrae in 3D CT scans. Our primary contribution is a new Domain Sanity Loss (DSL) function for unsupervised domain adaptation. We achieve results that are on par with the current state-of-the-art algorithms for full supervised learning while using about 20 times fewer labels. This is a very interesting instance of a data-centric approach to be pursued further in our research.</p>

<p>Additional applications include the <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/verbesserung-der-qualitaet-von-ct-bildern-mit-ki-und-deep-learning/">reduction of motion artifacts in CT images</a>, which can significantly reduce the risk for patients to develop secondary cancer during radiation therapy; the <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/videoanalyse-zur-datengesteuerten-pflege-von-intensivpatienten/">automated monitoring</a> of patients in intensive care; or the <a href="https://www.zhaw.ch/en/engineering/institutes-centres/init/news/news/event-news/neue-publikation-welche-eine-methode-zur-homogenisierung-von-daten-fuer-die-covid-erkennung-aus-ct-bildern-vorstellt/">homogenization of data</a> to train large, bias-free medical imaging models, as we showed in the context of the COVID-19 spread.</p>

<h4>Selected references</h4>
<ul>
    <li>Tuggener, L., Schmidhuber, J., and Stadelmann, T. (2022). <a href="https://doi.org/10.3389/fcomp.2022.1041703">Is it enough to optimize CNN architectures on ImageNet?</a>. Frontiers in Computer Science, 4, 1041703.</li>
    <li>Knapp, E., Battaglia, M., Stadelmann, T., Jenatsch, S., and Ruhstaller, B., 2021. <a href="https://stdm.github.io/downloads/papers/SDS_2021b.pdf">XGBoost Trained on Synthetic Data to Extract Material Parameters of Organic Semiconductors</a>. In Proceedings of the 8th Swiss Conference on Data Science (SDS'21), Lucerne, Switzerland, 2021.</li>
    <li>Amirian, M., Montoya‐Zegarra, J. A., Herzig, I., Eggenberger Hotz, P., Lichtensteiger, L., Morf, M., Züst, A., Paysan, P., Peterlik, I., Scheib, S., Füchslin, R. M., Stadelmann, T., and Schilling, F. P. (2023). <a href="https://doi.org/10.1002/mp.16405">Mitigation of motion‐induced artifacts in cone beam computed tomography using deep convolutional neural networks</a>. Medical Physics, 50(10), 6228-6242.</li>
    <li>Sager, P., Salzmann, S., Burn, F., and Stadelmann, T., 2022. <a href="https://www.mdpi.com/2313-433X/8/8/222/pdf">Unsupervised Domain Adaptation for Vertebrae Detection and Identification in 3D CT Volumes Using a Domain Sanity Loss</a>. J. Imaging 2022, 8(8), 222, MDPI, Basel, Switzerland.</li>
</ul>
</details>


<a name="documents"></a>
<details>
<summary><b>Document recognition</b></summary>

<img alt="Deep Watershed Detector architecture" src="http://stdm.github.io/images/dwd.jpg"/>

<p>We have applied our skills in pattern recognition frequently to use cases in document recognition, for example to convert music scores to machine-readable form. Written music is a large and important part of cultural heritage worldwide. While there are many archives containing thousands of music scores, they are paper-based, so public access is cumbersome or even impossible. Digitization of these scores has for a long time been impossible due to the non-availability of scanning software that can convert hand-written scores to machine-readable format (Optical Music Recognition – OMR). Our DeepScore and RealScore projects aimed at bringing bleeding edge technology form computer vision the field of OMR. The impact of OMR on how we curate, preserve and access music manuscripts cannot be overstated. Fully functional OMR would lead to a democratization of the musical cultural heritage by enabling cheap and efficient access by everyone. It would also enable more efficient music training, and enable orchestras to run cheaper and rehearse more efficiently.</p>

<p>To facilitate deep learning for OMR, we built the <a href="http://stdm.github.io/downloads/papers/ICPR_2018a.pdf">DeepScores</a> <a href="https://tuggeluk.github.io/deepscores/">dataset</a> with the goal of advancing the state-of-the-art in small object recognition by placing the question of object recognition in the context of scene understanding. DeepScores contains high quality images of musical scores, partitioned into 300'000 sheets of written music that contain symbols of different shapes and sizes. With close to a hundred million small objects, this makes our dataset not only unique, but also the largest public dataset. DeepScores comes with ground truth for object classification, detection and semantic segmentation. We provide baseline performances for object classification and intuition for the inherent difficulty that DeepScores poses to state-of-the-art object detectors like YOLO or R-CNN.</p>

<p>We introduced a novel object detection method, based on synthetic energy maps and the watershed transform, called <a href="http://stdm.github.io/downloads/papers/ISMIR_2018.pdf">Deep Watershed Detector (DWD)</a>. Our method is specifically tailored to deal with high resolution images that contain a large number of very small objects and is therefore able to process full pages of written music. We present state-of-the-art detection results of common music symbols and show DWD's ability to work with synthetic scores equally well as on handwritten music. Further results in making OMR more robust trhough <em>domain adaptation</em> can also be found <a href="https://www.zhaw.ch/en/about-us/news/news-releases/news-detail/event-news/realscore-scannen-von-real-world-noten-fuer-ein-digitales-notenpult/">here</a>.</p>

<p>Current work focuses on building a foundation model for document recognition, based on the insight that natural images and scans of documents for human consumption are very different in kind, hence need different inductive biases: Document recognition is better understood as transcription (of one format for information losslessly into another) rather than recognition.</p>

<h4>Selected references</h4>
<ul>
    <li>Tuggener, L., Emberger, R., Ghosh, A., Sager, P., Satyawan, Y. P., Montoya, J., Goldschagg, S., Seibold, F., Gut, U., Ackermann, P., Schmidhuber, J., and Stadelmann, T. (2024). <a href="https://doi.org/10.5334/tismir.157">Real world music object recognition</a>. Transactions of the International Society for Music Information Retrieval, 7(1), 1-14.</li>
    <li>Schmitt-Koopmann, F. M., Huang, E. M., Hutter, H. P., Stadelmann, T., and Darvishy, A. (2022). <a href="https://ieeexplore.ieee.org/document/9869643">FormulaNet: A benchmark dataset for mathematical formula detection</a>. IEEE Access, 10, 91588-91596.</li>
    <li>Tuggener, L., Elezi, I., Schmidhuber, J. and Stadelmann, T., 2018. <a href="https://stdm.github.io/downloads/papers/ISMIR_2018.pdf">Deep watershed detector for music object recognition</a>. In 19th International Society for Music Information Retrieval Conference, Paris, 23.-27. September 2018. Society for Music Information Retrieval.</li>
</ul>
</details>


<a name="l2l"></a>
<details>
<summary><b>Meta learning</b></summary>

<img alt="Learning to cluster model architecture" src="http://stdm.github.io/images/l2c_architecture.jpg"/>
<img alt="Example clusterings" src="http://stdm.github.io/images/l2c_clustering.jpg"/>

<p>Meta learning, or learning to learn is very interesting from the perspective of what learning in machines and beyond actually means. We have for instance built a novel end-to-end neural network architecture that, once trained, directly outputs a probabilistic clustering of a batch of input examples in one pass. It estimates a distribution over the number of clusters and, for each number of clusters up to a maximum, distributions over the respective data partitioning. The neural network is trained in a supervised fashion to group data by any perceptual similarity criterion based on pairwise labels (same/different group). It does not expect to have seen any of the groups that appear during model application already during training. We demonstrate promising performance on high-dimensional data like images (COIL-100) and speech (TIMIT). We call this <a href="http://stdm.github.io/downloads/papers/ANNPR_2018a.pdf">learning to cluster</a>. We have also produced a survey and some novel results on the more general topic of <a href="https://stdm.github.io/downloads/papers/SDS_2019.pdf">meta learning</a>.</p>

<h4>Selected references</h4>
<ul>
    <li>Tuggener, L., Amirian, M., Benites, F., von Däniken, P., Gupta, P., Schilling, F. P., and Stadelmann, T. (2020). <a href="https://www.mdpi.com/2673-2688/1/4/31/pdf">Design patterns for resource-constrained automated deep-learning methods</a>. AI, 1(4), 510-538.</li>
    <li>Meier, B.B., Elezi, I., Amirian, M., Dürr, O. and Stadelmann, T., 2018, September. <a href="https://stdm.github.io/downloads/papers/ANNPR_2018a.pdf">Learning Neural Models for End-to-End Clustering</a>. In IAPR Workshop on Artificial Neural Networks in Pattern Recognition (pp. 126-138). Springer, Cham.</li>
    <li>Tuggener, L., Amirian, M., Rombach, K., Lörwald, S., Varlet, A., Westermann, C., and Stadelmann, T., 2019, June. <a href="https://stdm.github.io/downloads/papers/SDS_2019.pdf">Automated Machine Learning in Practice: State of the Art and Recent Results</a>. In Proceedings of the 6th Swiss Conference on Data Science (SDS'19), Bern, Switzerland, June 14, 2019. IEEE.</li>
</ul>
</details>


<a name="voice"></a>
<details>
<summary><b>Voice recognition</b></summary>

<img alt="Architecture of the successful RNN model for speaker clustering" src="http://stdm.github.io/images/RNN_architecture.jpg"/>

<p><a href="http://stdm.github.io/downloads/papers/PhdThesis_2010">Thilo's PhD research</a> focused on the task of speaker clustering: grouping speech segments by speaker identity without prior knowledge of the number or identity of speakers (a prerequisite for e.g. content-based media indexing). While speaker identification usually achieved accuracy percentages in their high nineties, the state of the art for the more complex task of clustering performed an order of magnitude worse.</p>

<p>The 2009 ACM Multimedia paper on <a href="http://stdm.github.io/downloads/papers/ACMMM_2009.pdf">Unfolding Speaker Clustering Potential – a Biomimetic Approach</a> (see also the <a href="https://github.com/stdm/time_model">code</a>) not only analyzed this fact, but also identified deficiencies in modeling the sequence of speech features as the bottleneck responsible for the slump in performance. The prediction of potentially raising speaker clustering performance by an order of magnitude by better sequence modeling has led to exciting discoveries so far. We successively built deep learning models with more clustering capability to exploit the sequence information: a <a href="http://stdm.github.io/downloads/papers/MLSP_2016.pdf">simple CNN</a>, <a href="http://stdm.github.io/downloads/papers/MLSP_2017.pdf">CNN with optimized clustering loss</a> (fixed typo from "loos") and finally a <a href="http://stdm.github.io/downloads/papers/ANNPR_2018b.pdf">RNN</a> to improve the capturing of prosodic voice information, to reduce the error rate for pure voice comparison by the predicted rate (see <a href="https://github.com/stdm/ZHAW_deep_voice">code</a>). Additionally, using a <a href="http://stdm.github.io/downloads/papers/ICPR_2018b.pdf">different clustering algorithm</a> on top of the simple CNN feature embeddings also proved valuable.</p>

<p>This line of research has also lead to work on other audio processing tasks like media segmentation and classification, musical instrument recognition, audio fingerprinting, or voice transfer, mainly driven forward in student thesis projects.</p>

<h4>Selected references</h4>
<ul>
    <li>Neururer, D., Dellwo, V., and Stadelmann, T. (2024). <a href="https://doi.org/10.1016/j.patrec.2024.03.016">Deep neural networks for automatic speaker recognition do not learn supra-segmental temporal features</a>. Pattern Recognition Letters.</li>
    <li>Lukic, Y., Vogt, C., Dürr, O. and Stadelmann, T., 2016. <a href="https://stdm.github.io/downloads/papers/MLSP_2016.pdf">Speaker identification and clustering using convolutional neural networks</a>. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), Vietri sul Mare, Italy, 13-16 Sept. 2016. IEEE.</li>
    <li>Stadelmann, T. and Freisleben, B., 2009, October. <a href="https://stdm.github.io/downloads/papers/ACMMM_2009.pdf">Unfolding speaker clustering potential: a biomimetic approach</a>. In Proceedings of the 17th ACM international conference on Multimedia (pp. 185-194). ACM.</li>
</ul>
</details>


<a name="datascience"></a>
<details>
<summary><b>Data science</b></summary>

<img alt="The data science skill set map" src="http://stdm.github.io/images/skillset.jpg"/>

<p>Thilo helped in creating one of Europe's first dedicated research centers for data science, the <a href="http://www.zhaw.ch/datalab">ZHAW Datalab</a>, and lead it until 2018. Subsequently, he and colleagues created one of Switzerland's first continuing education programs in data science, the <a href="https://weiterbildung.zhaw.ch/de/school-of-engineering/programm/mas-data-science.html">MAS Data Science</a>, where he developed the machine learning teaching. In 2015, we started rolling out the successful Datalab collaboration model country-wide in founding the <a href="https://data-innovation.org/">Data Innovation Alliance</a>, a network of industrial and academic partner institutions that also furthered the <a href="https://sds2022.ch/">Swiss Conference on Data Science</a> series of events that <a href="https://www.zhaw.ch/en/research/inter-school-cooperation/datalab-the-zhaw-data-science-laboratory/sds2014/">started in Winterthur</a>. The experience gained in these activities, together with the feedback from the applied research projects described above, lead to a <a href="https://stdm.github.io/data-science-book/">book</a> co-edited together with colleagues <a href="http://www.zhaw.ch/=bram">Martin Braschler</a> and <a href="http://www.zhaw.ch/=stog">Kurt Stockinger</a>.</p>

<p>In 2021, we co-chaired the <a href="https://www.sds2022.ch/1st-international-symposium-on-the-science-of-data-science">1st International Symposium on the Science of Data Science</a>. In the course of reviewing the development of the field in the past decade, we came to the conclusion that it is <em>data centrism</em> – the reliance on data itself, in mindset, methods and products – that makes data science more than the sum of its parts, as this is not done in any other discipline.</p>

<h4>Selected references</h4>
<ul>
    <li>Stadelmann, T., Klamt, T., and Merkt, P. H., 2022. <a href="https://stdm.github.io/downloads/papers/AoDSA_2022a.pdf">Data Centrism and the Core of Data Science as a Scientific Discipline</a>. Archives of Data Science, Series A 8(2), pp.1-16, April 2022.</li>
    <li>Braschler, M., Stadelmann, T., and Stockinger, K., (Eds.), 2019. <a href="https://stdm.github.io/data-science-book/">Applied Data Science - Lessons Learned for the Data-Driven Business</a>. Springer.</li>
    <li>Stadelmann, T., Stockinger, K., Braschler, M., Cieliebak, M., Baudinot, G., Dürr, O. and Ruckstuhl, A., 2013. <a href="https://stdm.github.io/downloads/papers/ECSS_2013.pdf">Applied data science in Europe: challenges for academia in keeping up with a highly demanded topic</a>. In 9th European Computer Science Summit, Amsterdam, October 8–9, 2013.</li>
</ul>
</details>


<a name="collaborations"></a>
## Collaborations

We usually collaborate with industry to work on novel pattern recognition use cases after funding is secured. Partners come from start-ups, SMEs and multi-national enterprises alike. It is actually helpful, in our experience over more than a decade, to work across domains (e.g., industrial production, medicine/health, entertainment, ...): The methodical questions are very comparable (robustness, transferability, ...), while the different application areas help to not make subsequent partners competitors. For any concrete project, we build the team that is best suited to solve the particular challenges, which often leads to collaborations with other research groups from the ZHAW.

<details>
<summary><b>Research partnerships</b></summary>

We collaborate a lot with different universities and research institutions worldwide, also for joint supervision of our PhD students.


<a href="url"></a>

<ul>
	<li><a href="https://sites.uml.edu/abl">Prof. Benjamin Grewe</a> (neuroinformatics and machine learning) of ETH Zurich</li>
	<li><a href="https://www.fias.science/en/life-and-neurosciences/research-groups/christoph-von-der-malsburg/">Prof. Christoph von der Malsburg</a> (neuroscience) of Frankfurt Institute of Advanced Studies</li>
	<li><a href="http://www.dsi.unive.it/~pelillo/">Prof. Marcello Pelillo</a> (pattern recognition) of Ca'Foscari University of Venice</li>
	<li><a href="http://people.idsia.ch/~juergen/">Prof. Juergen Schmidhuber</a> (AI, deep learning) of IDSIA and KAUST</li>
	<li><a href="https://sites.uml.edu/abl/">Prof. Anna Yaroslavsky</a> (biophotonics) of UMass Lovell</li>
	<li><a href="https://www.ru.nl/en/about-us/news/carmody-grey-appointed-professor-by-special-appointment-of-integral-ecology">Prof. Carmody Grey</a> (theology, integral ecology) of Radboud Universiteit</li>
	<li><a href="https://www.unifr.ch/glaubeundgesellschaft/en/center/people/team-en/oliver-duerr.html">Dr. Oliver Duerr</a> (techno-theology, ethics, faith & society) of University of Fribourg</li>
	<li><a href="https://mlo.epfl.ch/">Prof. Martin Jaggi</a> (machine learning, optimisation) of EPFL</li>
	<li><a href="https://www.empa.ch/web/s799/mirko-kovac">Prof. Mirko Kovac</a> (sustainability robotics) EMPA/EPFL</li>
	<li><a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html">Prof. Davide Scaramuzza</a> (robotics, perception) University of Zurich</li>
</ul>

</details>

If you are interested in a collaboration, please [contact](http://www.zhaw.ch/=stdm) me.


<a name="publications"></a>
## Publications

Compare bibliometrics on [Google scholar](https://scholar.google.ch/citations?user=6U6ZXzUAAAAJ&hl=en) and [ResearchGate](https://www.researchgate.net/profile/Thilo_Stadelmann2).

#### 2025

Thilo Stadelmann. [**Wegweiser Künstliche Intelligenz: Verstehen, anwenden und zuversichtlich Zukunft gestalten**](https://stdm.github.io/downloads/papers/KIW_2025.pdf). In: Sebastian Hersberger and Christian Hugo Hoffmann (Editors). "Wie die Künstliche Intelligenz die Wirtschaft verändert - Überblick über die theoretischen Grundlagen und Praxisbeispiele entlang von Ökosystemen", **Springer**, 2025.


#### 2024

Ahmed Begga, Waqar Ali, Gabriel Niculescu, Francisco Escolano, Thilo Stadelmann, and Marcello Pelillo. [**Community-Hop: Enhancing Node Classification through Community Preference**](https://stdm.github.io/downloads/papers/S+SSPR_2024.pdf). In: Proceedings of the Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition and Structural and Syntactic Pattern Recognition (**S+SSPR**), 2024.

Waqar Ali, Sebastiano Vascon, Thilo Stadelmann, and Marcello Pelillo. [**Hierarchical Glocal Attention Pooling for Graph Classification**](https://stdm.github.io/downloads/papers/PRL_2024b.pdf). In: **Pattern Recognition Letters** 186, pp. 71-77, Elsevier, September 2024, DOI [10.1016/j.patrec.2024.09.009](https://doi.org/10.1016/j.patrec.2024.09.009).

Pascal J. Sager, Jan M. Deriu, Benjamin F. Grewe, Thilo Stadelmann, and Christoph von der Malsburg. [**The Dynamic Net Architecture: Learning Robust and Holistic Visual Representations Through Self-Organizing Networks**](https://stdm.github.io/downloads/papers/ArXiv_2024.pdf). In: **arXiv preprint**, [arXiv:2407.05650](https://arxiv.org/pdf/2407.05650.pdf), July 2024.

Peter Bolt, Volker Ziebart, Christian Jaeger, Nicolas Schmid, Thilo Stadelmann, and Rudolf M. Füchslin. [**A Simulation Study on Energy Optimization in Building Control with Reinforcement Learning**](https://stdm.github.io/downloads/papers/ANNPR_2024.pdf). In: Proceedings of the 11th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'24**), Springer, Montreal, Canada, October 10-12, 2024.

Peter R. Jermain, Martin Oswald, Tenzin Langdun, Santana Wright, Ashraf Khan, Thilo Stadelmann, Ahmed Abdulkadir, and Anna N. Yaroslavsky. [**Deep-learning-based Cell Segmentation for Rapid Optical Cytopathology of Thyroid Cancer**](https://www.nature.com/articles/s41598-024-64855-2.epdf). In: **Scientific Reports** 14, article nr. 16389 (2024), Nature, July 2024, DOI [10.1038/s41598-024-64855-2](https://doi.org/10.1038/s41598-024-64855-2).

Felix M. Schmitt-Koopmann, Elaine M. Huang, Hans-Peter Hutter, Thilo Stadelmann, and Alireza Darvishy. [**MathNet: A Data-Centric Approach for Printed Mathematical Expression Recognition**](https://ieeexplore.ieee.org/document/10538105). In: **IEEE Access**, May 2024, DOI [10.1109/ACCESS.2024.3404834](https://dx.doi.org/10.1109/ACCESS.2024.3404834).

Ali Dashti, Thilo Stadelmann, and Thomas Kohl. [**Machine learning for robust structural uncertainty quantification in fractured reservoirs**](https://stdm.github.io/downloads/papers/Geothermics_2024.pdf). In: **Geothermics** 120, p. 103012, Elsevier, June 2024, DOI [10.1016/j.geothermics.2024.103012](https://doi.org/10.1016/j.geothermics.2024.103012).

Daniel Neururer, Volker Dellwo, and Thilo Stadelmann. [**Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features**](https://stdm.github.io/downloads/papers/ArXiv_2023b.pdf). In: **Pattern Recognition Letters** 181, pp. 64-49, Elsevier, May 2024, DOI [10.1016/j.patrec.2024.03.016](https://doi.org/10.1016/j.patrec.2024.03.016).
	
Peng Yan, Ahmed Abdulkadir, Giulia Aguzzi, Gerrit A. Schatte, Benjamin F. Grewe, and Thilo Stadelmann. [**Automated process monitoring in injection molding via representation learning and setpoint regression**](https://stdm.github.io/downloads/papers/SDS_2024c.pdf). In: Proceedings of the 11th IEEE Swiss Conference on Data Science (**SDS'24**), Zurich, Switzerland, May 31, 2024, DOI [10.1109/SDS60720.2024.00027](https://doi.org/10.1109/SDS60720.2024.00027).

Lukas Tuggener, Pascal Sager, Yassine Taoudi-Benchekroun, Benjamin F. Grewe, and Thilo Stadelmann. [**So you want your private LLM at home? A survey and benchmark of methods for efficient GPTs**](https://stdm.github.io/downloads/papers/SDS_2024b.pdf). In: Proceedings of the 11th IEEE Swiss Conference on Data Science (**SDS'24**), Zurich, Switzerland, May 31, 2024, DOI [10.1109/SDS60720.2024.00036](https://doi.org/10.1109/SDS60720.2024.00036).

Benjamin Meyer, Thilo Stadelmann, and Marcel Lüthi. [**ScalaGrad: A Statically Typed Automatic Differentiation Library for Safer Data Science**](https://stdm.github.io/downloads/papers/SDS_2024a.pdf). In: Proceedings of the 11th IEEE Swiss Conference on Data Science (**SDS'24**), Zurich, Switzerland, May 31, 2024, DOI [10.1109/SDS60720.2024.00040](https://doi.org/10.1109/10.1109/SDS60720.2024.00040).

Peter R. Jermain, Martin Oswald, Tenzin Langdun, Santana Wright, Ashraf Khan, Thilo Stadelmann, Ahmed Abdulkadir, and Anna N. Yaroslavsky. [**Rapid Optical Cytology with Deep Learning-Based Cell Segmentation for Diagnosis of Thyroid Lesions**](https://stdm.github.io/downloads/papers/BioMed_2024.pdf). In: Proceedings of the 2024 **Optica Biophotonics Congress: Biomedical Optics**, Fort Lauderdale, FL, USA, April 07-10, 2024.

Lukas Tuggener, Raphael Emberger, Adhiraj Ghosh, Pascal Sager, Yvan Putra Satyawan, Javier Montoya, Simon Goldschagg, Florian Seibold, Urs Gut, Philipp Ackermann, Jürgen Schmidhuber, and Thilo Stadelmann. [**Real World Music Object Recognition**](https://stdm.github.io/downloads/papers/TISMIR_2023.pdf). In: **TISMIR** 7(1), 1–14, 2024. DOI [10.5334/tismir.157](https://doi.org/10.5334/tismir.157).

Peng Yan, Ahmed Abdulkadir, Paul-Philipp Luley, Matthias Rosenthal, Gerrit A. Schatte, Benjamin F. Grewe, and Thilo Stadelmann. [**A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions**](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10379639). In: **IEEE Access**, January 2024. DOI [10.1109/ACCESS.2023.3349132](https://doi.org/10.1109/ACCESS.2023.3349132).


#### 2023

Jan Segessenmann, Thilo Stadelmann, Andrew Davison, and Oliver Dürr. [**Assessing Deep Learning: A Work Program for the Humanities in the Age of Artificial Intelligence**](https://stdm.github.io/downloads/papers/AIEthics_2023.pdf). In: **AI and Ethics**, Springer, November 30, 2023, DOI [10.1007/s43681-023-00408-z](https://link.springer.com/article/10.1007/s43681-023-00408-z) (see also extended **SSRN preprint**, [ssrn.4554234](https://ssrn.com/abstract=4554234), August 28, 2023. DOI [10.2139/ssrn.4554234](http://dx.doi.org/10.2139/ssrn.4554234)).

Lukas Tuggener, Thilo Stadelmann, and Jürgen Schmidhuber. [**Efficient Rotation Invariance in Deep Neural Networks through Artificial Mental Rotation**](https://stdm.github.io/downloads/papers/ArXiv_2023c.pdf). In: **arXiv preprint**, [arXiv:2311.08525](https://arxiv.org/pdf/2311.08525.pdf), November 2023.

Matthia Battaglia, Ennio Comi, Thilo Stadelmann, Roman Hiestand, Beat Ruhstaller, and Evelyne Knapp. [**Deep Ensemble Inverse Model for Image-Based Estimation of Solar Cell Parameters**](https://stdm.github.io/downloads/papers/APLML_2023.pdf). In: **APL Machine Learning** 1(3). 01. September 2023. DOI [10.1063/5.0139707](https://doi.org/10.1063/5.0139707).

Raphael Emberger, Jens Michael Boss, Daniel Baumann, Marko Seric, Shufan Huo, Lukas Tuggener, Emanuela Keller, and Thilo Stadelmann. [**Video object detection for privacy-preserving patient monitoring in intensive care**](https://stdm.github.io/downloads/papers/SDS_2023b.pdf). In: Proceedings of the 10th IEEE Swiss Conference on Data Science (**SDS'23**), Zurich, Switzerland, 2023.

Paul-Philipp Luley, Jan M. Deriu, Peng Yan, Gerrit A. Schatte, and Thilo Stadelmann. [**From Concept to Implementation: The Data-Centric Development Process for AI in Industry**](https://stdm.github.io/downloads/papers/SDS_2023a.pdf). In: Proceedings of the 10th IEEE Swiss Conference on Data Science (**SDS'23**), Zurich, Switzerland, 2023.

Mohammadreza Amirian, Javier A. Montoya-Zegarra, Lukas Lichtensteiger, Ivo Herzig, Peter Eggenberger Hotz,  Marco Morf, Alexander Züst, Rudolf Marcel Füchslin, Pascal Paysan, Igor Peterlik, Stefan Scheib, Thilo Stadelmann, and Frank-Peter Schilling. [**Mitigation of Motion-Induced Artifacts in Cone Beam Computed Tomography using Deep Convolutional Neural Networks**](https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.16405). **Med. Phys.** 50: 6228-6242, Wiley, March 2023. DOI [10.1002/mp.16405](https://doi.org/10.1002/mp.16405).

Waqar Ali, Sebastiano Vascon, Thilo Stadelmann, and Marcello Pelillo. [**Quasi-CliquePool: Hierarchical Graph Pooling for Graph Classification**](https://stdm.github.io/downloads/papers/GMLR_2023.pdf). ACM SAC 2023 Track on Graph Models for Learning and Recognition (**GMLR**), Tallinn, Estonia, March 27 - April 2, 2023. DOI [10.1145/3555776.3578600](https://doi.org/10.1145/3555776.3578600).

Thilo Stadelmann. [**KI als Chance für die angewandten Wissenschaften im Wettbewerb der Hochschulen**](https://stdm.github.io/downloads/papers/Buergenstock_2023.pdf). Workshop ("Atelier") at the **Bürgenstock-Konferenz der Schweizer Fachhochschulen und Pädagogischen Hochschulen** 2023, Luzern, Schweiz, 20. Januar 2023.


#### 2022

Lukas Tuggener, Jürgen Schmidhuber, and Thilo Stadelmann. [**Is it enough to optimize CNN architectures on ImageNet?**](https://stdm.github.io/downloads/papers/Frontiers_2022.pdf). Computer Vision - **Frontiers in Computer Science**, DOI [10.3389/fcomp.2022.1041703](https://doi.org/10.3389/fcomp.2022.1041703), 15 November 2022.

Felix M. Schmitt-Koopmann, Elaine M. Huang, Hans-Peter Hutter, Thilo Stadelmann, and Alireza Darvishy. [**FormulaNet: A Benchmark Dataset for Mathematical Formula Detection**](https://stdm.github.io/downloads/papers/Access_2022.pdf). **IEEE Access** 2022, 10, pp. 91588-91596, DOI [10.1109/ACCESS.2022.3202639](https://ieeexplore.ieee.org/document/9869643), August 2022.

Pascal Sager, Sebastian Salzmann, Felice Burn, and Thilo Stadelmann. [**Unsupervised Domain Adaptation for Vertebrae Detection and Identification in 3D CT Volumes Using a Domain Sanity Loss**](https://www.mdpi.com/2313-433X/8/8/222/pdf). **J. Imaging** 2022, 8(8), 222, MDPI, Basel, Switzerland. DOI [10.3390/jimaging8080222](https://doi.org/10.3390/jimaging8080222).

Christoph von der Malsburg, Benjamin F. Grewe, and Thilo Stadelmann. [**Making Sense of the Natural Environment**](https://stdm.github.io/downloads/papers/KogWis_2022.pdf). Proceedings of the **KogWis 2022 - Understanding Minds** Biannual Conference of the German Cognitive Science Society, Freiburg, Germany, September 5-7, 2022.

Christoph von der Malsburg, Thilo Stadelmann, and Benjamin F. Grewe. [**A Theory of Natural Intelligence**](https://stdm.github.io/downloads/papers/ArXiv_2022.pdf). **arXiv preprint**, [arXiv:2205.00002](https://arxiv.org/abs/2205.00002), April 2022.

Frank-Peter Schilling, Dandolo Flumini, Rudolf M. Füchslin, Elena Gavagnin, Armando Geller, Silvia Quarteroni and Thilo Stadelmann. [**Foundations of Data Science: A Comprehensive Overview Formed at the 1st International Symposium on the Science of Data Science**](https://stdm.github.io/downloads/papers/AoDSA_2022b.pdf). **Archives of Data Science, Series A 8(2)**, pp. 1-21, 2022. DOI [10.5445/IR/1000146422](https://dx.doi.org/10.5445/IR/1000146422).

Ivo Herzig, Pascal Paysan, Stefan Scheib, Frank-Peter Schilling, Javier Montoya, Mohammadreza Amirian, Thilo Stadelmann, Peter Eggenberger, Rudolf M. Fuechslin, and Lukas Lichtensteiger. **Deep Learning-Based Simultaneous Multi-Phase Deformable Image Registration of Sparse 4D-CBCT**. In: Proceedings of the American Association of Physics in Medicine Annual Meeting (**AAPM'22**), Washington, DC, USA, July 10-14, 2022.

Thilo Stadelmann, Tino Klamt, and Philipp H. Merkt. [**Data Centrism and the Core of Data Science as a Scientific Discipline**](https://stdm.github.io/downloads/papers/AoDSA_2022a.pdf). **Archives of Data Science, Series A 8(2)**, pp.1-16, April 2022. DOI [10.5445/IR/1000143637](https://dx.doi.org/10.5445/IR/1000143637).

Andreas Geyer-Schultz and Thilo Stadelmann (Editors). [**Archives of Data Science, Series A 8(2)**](https://www.archivesofdatascience.org/journals/series_a/publications#articles), April 2022. **Special Issue**.

Frank-Peter Schilling and Thilo Stadelmann (Editors). [**Special Issue "Advances in Deep Neural Networks for Visual Pattern Recognition**](https://www.mdpi.com/journal/jimaging/special_issues/deep_neural_network), **J. Imaging**, MDPI, March 2022. 


#### 2021

Samuel Wehrli, Corinna Hertweck, Mohammadreza Amirian, Stefan Glüge, and Thilo Stadelmann. [**Bias, awareness and ignorance in deep-learning-based face recognition**](https://stdm.github.io/downloads/papers/AIEthics_2021.pdf). **AI and Ethics**, DOI [10.1007/s43681-021-00108-6](https://link.springer.com/article/10.1007%2Fs43681-021-00108-6), Springer, October 27, 2021.

Mohammadreza Amirian, Javier A. Montoya-Zegarra, Jonathan Gruss, Yves D. Stebler, Ahmet Selman Bozkir, Marco Calandri, Friedhelm Schwenker, and Thilo Stadelmann. [**PrepNet: A Convolutional Auto-Encoder to Homogenize CT Scans for Cross-Dataset Medical Image Analysis**](https://stdm.github.io/downloads/papers/CISP_BMEI_2021.pdf). In: Proceedings of the 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (**CISP-BMEI'21**), Shanghai, China, 2021.

Thilo Stadelmann, Julian Keuzenkamp, Helmut Grabner, and Christoph Würsch. [**The AI Atlas: Didactics for Teaching AI and Machine Learning On-Site, Online, and hybrid**](https://www.mdpi.com/2227-7102/11/7/318/pdf). **Educ. Sci.** 2021, 11, 318, MDPI, Basel, Switzerland, June 25, 2021.

Evelyne Knapp, Mattia Battaglia, Thilo Stadelmann, Sandra Jenatsch, and Beat Ruhstaller. [**XGBoost Trained on Synthetic Data to Extract Material Parameters of Organic Semiconductors**](https://stdm.github.io/downloads/papers/SDS_2021b.pdf). In: Proceedings of the 8th Swiss Conference on Data Science (**SDS'21**), Lucerne, Switzerland, 2021. **[Best paper award](https://twitter.com/thilo_on_data/status/1402663898289950727)**.

Niclas Simmler, Pascal Sager, Philipp Andermatt, Ricardo Chavarriaga, Frank-Peter Schilling, Matthias Rosenthal, and Thilo Stadelmann. [**A Survey of Un-, Weakly-, and Semi-Supervised Learning Methods for Noisy, Missing and Partial Labels in Industrial Vision Applications**](https://stdm.github.io/downloads/papers/SDS_2021a.pdf). In: Proceedings of the 8th Swiss Conference on Data Science (**SDS'21**), Lucerne, Switzerland, 2021.


#### 2020

Thilo Stadelmann, and Christoph Würsch. [**Maps for an Uncertain Future: Teaching AI and Machine Learning Using the ATLAS Concept**](https://stdm.github.io/downloads/papers/TR_2020.pdf). Technical report (didactic concept), **ZHAW**, Winterthur, Switzerland, 2020.

Lukas Tuggener, Mohammadreza Amirian, Fernando Benites, Pius von Däniken, Prakhar Gupta, Frank-Peter Schilling, and Thilo Stadelmann. [**Design Patterns for Resource-Constrained Automated Deep-Learning Methods**](https://www.mdpi.com/2673-2688/1/4/31/pdf). **AI** section "Intelligent Systems: Theory and Applications" 1(4):510-538, MDPI, Basel, Switzerland, November 06, 2020.

Lukas Tuggener, Yvan Putra Satyawan, Alexander Pacha, Jürgen Schmidhuber, and Thilo Stadelmann. [**The DeepScoresV2 Dataset and Benchmark for Music Object Detection**](https://stdm.github.io/downloads/papers/ICPR_2020.pdf). In: Proceedings of the 25th International Conference on Pattern Recognition (**ICPR'20**), IAPR, Milan, Italy, January 10-15 (online), 2021.

Frank-Peter Schilling, and Thilo Stadelmann (Eds.). **Artificial Neural Networks in Pattern Recognition - 9th IAPR TC3 Workshop, ANNPR 2020, Winterthur, Switzerland, September 2–4, 2020, Proceedings**. Lecture Notes in Artificial Intelligence 12294, Springer, September 02, 2020.

Dano Roost, Ralph Meier, Giovanni Toffetti Carughi, and Thilo Stadelmann. [**Combining Reinforcement Learning with Supervised Deep Learning for Neural Active Scene Understanding**](https://stdm.github.io/downloads/papers/AVHRC_2020.pdf). In: Proceedings of the Active Vision and Perception in Human(-Robot) Collaboration Workshop at IEEE RO-MAN 2020 (**AVHRC'20**), online, August 31, 2020. **[Dr. Waldemar Jucker award 2020](https://www.gst.ch/aktivit%C3%A4ten/f%C3%B6rderpreis/)**.

Stefan Glüge, Mohammadreza Amirian, Dandolo Flumini, and Thilo Stadelmann. [**How (Not) to Measure Bias in Face Recognition Networks**](https://stdm.github.io/downloads/papers/ANNPR_2020.pdf). In: Proceedings of the 9th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'20**), Springer, LNAI, Winterthur, Switzerland, September 02-04, 2020. **Top-5 paper, invitation for extended journal paper**.

Mohammadreza Amirian, Lukas Tuggener, Ricardo Chavarriaga, Yvan Putra Satyawan, Frank-Peter Schilling, Friedhelm Schwenker, and Thilo Stadelmann. [**Two to Trust: AutoML for Safe Modelling and Interpretable Deep Learning for Robustness**](https://stdm.github.io/downloads/papers/TAILOR_2020.pdf). In: Proceedings of the 1st **TAILOR Workshop on Trustworthy AI at ECAI 2020**, Santiago de Compostela, Spain, September 04-06, 2020. Springer.

Dano Roost, Ralph Meier, Stephan Huschauer, Erik Nygren, Adrian Egli, Andreas Weiler, and Thilo Stadelmann. [**Improving Sample Efficiency and Multi-Agent Communication in RL-based Train Rescheduling**](https://stdm.github.io/downloads/papers/SDS_2020.pdf). In: Proceedings of the 7th Swiss Conference on Data Science (**SDS'20**), Lucerne, Switzerland, June 26, 2020. IEEE. **[Best poster presentation award](https://twitter.com/i/status/1258367206846541825)**.


#### 2019

Mohammadreza Amirian, Katharina Rombach, Lukas Tuggener, Frank-Peter Schilling, and Thilo Stadelmann. [**Efficient Deep CNNs for Cross-Modal Automated Computer Vision under Time and Space Constraints**](https://stdm.github.io/downloads/papers/ECML_PKDD_2019.pdf). In: **AutoCV2 Workshop** at European Conference on Machine Learning / European Conference on Principles and Practice of Knowledge Discovery in Databases (**ECML-PKDD**), Wuerzburg, Germany, September 16-19, 2019.

Kurt Stockinger, Martin Braschler, and Thilo Stadelmann. [**Lessons Learned from Challenging Data Science Case Studies**](https://stdm.github.io/downloads/papers/ADS_2019_LessonsLearned.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Lukas Hollenstein, Lukas Lichtensteiger, Thilo Stadelmann, Mohammadreza Amirian, Lukas Budde, Jürg Meierhofer, Rudolf M. Füchslin, and Thomas Friedli. [**Unsupervised Learning and Simulation for Complexity Management in Business Operations**](https://stdm.github.io/downloads/papers/ADS_2019_Complexity.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Thilo Stadelmann, Vasily Tolkachev, Beate Sick, Jan Stampfli, and Oliver Dürr. [**Beyond ImageNet - Deep Learning in Industrial Practice**](https://stdm.github.io/downloads/papers/ADS_2019_DeepLearning.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Jürg Meierhofer, Thilo Stadelmann, and Mark Cieliebak. [**Data Products**](https://stdm.github.io/downloads/papers/ADS_2019_DataProducts.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Thilo Stadelmann, Kurt Stockinger, Gundula Heinatz-Bürki, and Martin Braschler. [**Data Scientists**](https://stdm.github.io/downloads/papers/ADS_2019_DataScientists.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Martin Braschler, Thilo Stadelmann, and Kurt Stockinger. [**Data Science**](https://stdm.github.io/downloads/papers/ADS_2019_DataScience.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Thilo Stadelmann, Martin Braschler, and Kurt Stockinger. [**Introduction to Applied Data Science**](https://stdm.github.io/downloads/papers/ADS_2019_Introduction.pdf). In: Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). ["Applied Data Science - Lessons Learned for the Data-Driven Business"](https://stdm.github.io/data-science-book/). **Springer**, 2019.

Martin Braschler, Thilo Stadelmann, and Kurt Stockinger (Editors). [**Applied Data Science - Lessons Learned for the Data-Driven Business**](https://stdm.github.io/downloads/papers/ADS_2019_Preface.pdf). **Springer**, 2019.

Thilo Stadelmann. [**Wie maschinelles Lernen den Markt verändert**](https://stdm.github.io/downloads/papers/FCW_2019.pdf). In: Reinhard Haupt, Stephan Schmitz (Editors), "Digitalisierung: Datenhype mit Werteverlust? Ethische Perspektiven für eine Schlüsseltechnologie", pp. 67-79, ISBN 377516040X, **SCM Hänssler**, 2019.

Lukas Tuggener, Mohammadreza Amirian, Katharina Rombach, Stefan Lörwald, Anastasia Varlet, Christian Westermann, and Thilo Stadelmann. [**Automated Machine Learning in Practice: State of the Art and Recent Results**](https://stdm.github.io/downloads/papers/SDS_2019.pdf). In: Proceedings of the 6th Swiss Conference on Data Science (**SDS'19**), Bern, Switzerland, June 14, 2019. IEEE.


#### 2018

Ismail Elezi, Lukas Tuggener, Marcello Pelillo, and Thilo Stadelmann. [**DeepScores and Deep Watershed Detection: current state and open issues**](https://stdm.github.io/downloads/papers/WoRMS_2018.pdf). In: Proceedings of the 1st International Workshop on Reading Music Systems (**WoRMS'18**), Paris, France, September 20, 2018.

Thilo Stadelmann, Mohammadreza Amirian, Ismail Arabaci, Marek Arnold, Gilbert François Duivesteijn, Ismail Elezi, Melanie Geiger, Stefan Lörwald, Benjamin Bruno Meier, Katharina Rombach, and Lukas Tuggener. [**Deep Learning in the Wild**](https://stdm.github.io/downloads/papers/ANNPR_2018d.pdf). In: Proceedings of the 8th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'18**), Springer, LNAI 11081, pp. 17-38, Siena, Italy, September 19-21, 2018. **Invited paper**.

Mohammadreza Amirian, Friedhelm Schwenker, and Thilo Stadelmann. [**Trace and Detect Adversarial Attacks on CNNs using Feature Response Maps**](https://stdm.github.io/downloads/papers/ANNPR_2018c.pdf). In: Proceedings of the 8th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'18**), Springer, LNAI 11081, pp. 346-358, Siena, Italy, September 19-21, 2018.

Thilo Stadelmann, Sebastian Glinski-Haefeli, Patrick Gerber, and Oliver Dürr. [**Capturing Suprasegmental Features of a Voice with RNNs for Improved Speaker Clustering**](https://stdm.github.io/downloads/papers/ANNPR_2018b.pdf). In: Proceedings of the 8th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'18**), Springer, LNAI 11081, pp. 333-345, Siena, Italy, September 19-21, 2018.

Benjamin Bruno Meier, Ismail Elezi, Mohammadreza Amirian, Oliver Dürr, and Thilo Stadelmann. [**Learning Neural Models for End-to-End Clustering**](https://stdm.github.io/downloads/papers/ANNPR_2018a.pdf). In: Proceedings of the 8th IAPR TC 3 Workshop on Artificial Neural Networks for Pattern Recognition (**ANNPR'18**), Springer, LNAI 11081, pp. 126-138, Siena, Italy, September 19-21, 2018.

Lukas Tuggener, Ismail Elezi, Jürgen Schmidhuber, and Thilo Stadelmann. [**Deep watershed detector for music object recognition**](https://stdm.github.io/downloads/papers/ISMIR_2018.pdf). In: Proceedings of the 19th International Society for Music Information Retrieval Conference (**ISMIR'18**), Paris, 23. - 27. September 2018. Paris: Society for Music Information Retrieval. DOI [10.21256/zhaw-3760](https://doi.org/10.21256/zhaw-3760).

Feliks Hibraj, Sebastiano Vascon, Thilo Stadelmann, and Marcello Pelillo. [**Speaker clustering using dominant sets**](https://stdm.github.io/downloads/papers/ICPR_2018b.pdf). In: Proceedings of the 24th International Conference on Pattern Recognition (ICPR 2018). 24th International Conference on Pattern Recognition (**ICPR'18**), Beijing, China, 20-28 August 2018. Beijing: IAPR. DOI [10.21256/zhaw-4254](https://doi.org/10.21256/zhaw-4254).

Lukas Tuggener, Ismail Elezi, Jürgen Schmidhuber, Marcello Pelillo, and Thilo Stadelmann. [**DeepScores: a dataset for segmentation, detection and classification of tiny objects**](https://stdm.github.io/downloads/papers/ICPR_2018a.pdf). In: Proceedings of the 24th International Conference on Pattern Recognition. 24th International Conference on Pattern Recognition (**ICPR'18**), Beijing, China, 20-28 August 2018. Beijing: IAPR. 1-6. DOI [10.21256/zhaw-4255](https://doi.org/10.21256/zhaw-4255).


#### 2017

Benjamin Meier, Thilo Stadelmann, Jan Stampfli, Marek Arnold, and Mark Cieliebak. [**Fully convolutional neural networks for newspaper article segmentation**](https://stdm.github.io/downloads/papers/ICDAR_2017.pdf). In: Proceedings of the 14th IAPR International Conference on Document Analysis and Recognition (**ICDAR'17**). 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), Kyoto Japan, November 13-15, 2017. Kyoto, Japan: CPS. DOI [10.21256/zhaw-1533](https://doi.org/10.21256/zhaw-1533).

Yanick X. Lukic, Carlo Vogt, Oliver Dürr, and Thilo Stadelmann. [**Learning Embeddings for Speaker Clustering Based on Voice Equality**](https://stdm.github.io/downloads/papers/MLSP_2017.pdf). In: Proceedings of the 27th IEEE International Workshop on Machine Learning for Signal Processing (**MLSP'17**). Roppongi, Tokyo, Japan: IEEE. DOI [10.21256/zhaw-3762](https://doi.org/10.21256/zhaw-3762).


#### 2016

Yanick Lukic, Carlo Vogt, Oliver Dürr, and Thilo Stadelmann. [**Speaker Identification and Clustering using Convolutional Neural Networks**](https://stdm.github.io/downloads/papers/MLSP_2016.pdf). In: Proceedings of IEEE International Workshop on Machine Learning for Signal Processing (**MLSP'16**). Salerno: IEEE. DOI [10.21256/zhaw-3761](https://doi.org/10.21256/zhaw-3761).

Kurt Stockinger, Thilo Stadelmann, and Andreas Ruckstuhl. [**Data Scientist als Beruf**](https://stdm.github.io/downloads/papers/HMD_2016.pdf). Big Data – Grundlagen, Systeme und Nutzungspotenziale, Springer Verlag, **Edition HMD** 59-81, 2016. DOI [10.1007/978-3-658-11589-0_4](https://doi.org/10.1007/978-3-658-11589-0_4).


#### 2015

Jean-Daniel Dessimoz, Jana Koehler, and Thilo Stadelmann. [**AI in Switzerland**](https://stdm.github.io/downloads/papers/AIMAG_2015.pdf). **AI Magazine**. 36(2), S. 102-105, 2015. DOI [10.21256/zhaw-3642](https://doi.org/10.21256/zhaw-3642). **Invited paper**.

Thilo Stadelmann, Mark Cieliebak, and Kurt Stockinger. [**Toward automatic data curation for open data**](https://stdm.github.io/downloads/papers/ERCIM_2015.pdf). **ERCIM News**. 2015(100), S. 32-33. DOI [10.21256/zhaw-3643](https://doi.org/10.21256/zhaw-3643).


#### 2014

Kurt Stockinger, and Thilo Stadelmann. [**Data Science für Lehre, Forschung und Praxis**](https://stdm.github.io/downloads/papers/HMD_2014.pdf). **HMD Praxis der Wirtschaftsinformatik**. 51(4), S. 469-479, 2014. DOI [10.21256/zhaw-3759](https://doi.org/10.21256/zhaw-3759).


#### 2013

Thilo Stadelmann, Kurt Stockinger, Martin Braschler, Mark Cieliebak, Gerold Baudinot, Oliver Dürr, and Andreas Ruckstuhl. [**Applied data science in Europe: challenges for academia in keeping up with a highly demanded topic**](https://stdm.github.io/downloads/papers/ECSS_2013.pdf). In: Proceedings of the 9th European Computer Science Summit (**ECSS'13**), Amsterdam, October 8–9, 2013.


#### 2012

Thilo Stadelmann, Sven Johr, Michael Ditze, Florian Dittman, and Viktor Fässler. [**FABELHAFT - Fahrerablenkung: Entwicklung eines Meta-Fahrerassistenzsystems durch Echtzeit-Audioklassifikation**](https://stdm.github.io/downloads/papers/VDIFASIS_2012.pdf). In Proceedings of 28. **VDI-VW Gemeinschaftstagung Fahrerassistenzsysteme und Integrierte Sicherheit '12**, Wolfsburg, Germany, October 10.-11., 2012. VDI Wissensforum.


#### 2010

Thilo Stadelmann. [**Voice Modeling Methods for Automatic Speaker Recognition**](https://stdm.github.io/downloads/papers/PhdThesis_2010.pdf). Dissertation, **Philipps-Universität Marburg**. [Available online, 2010](https://archiv.ub.uni-marburg.de/ubfind/Record/urn:nbn:de:hebis:04-z2010-0465?sid=1980300).

Thilo Stadelmann & Bernd Freisleben. [**On the MixMax Model and Cepstral Features for Noise-Robust Voice Recognition**](https://stdm.github.io/downloads/papers/TR_2010.pdf). Technical report, Philipps-Universität Marburg, April 2010.

Christian Beecks, Thilo Stadelmann, Bernd Freisleben, and Thomas Seidl. [**Visual Speaker Model Exploration**](https://stdm.github.io/downloads/papers/ICME_2010.pdf), In Proceedings of the IEEE International Conference on Multimedia and Expo (**ICME'2010**), pages 727-728, Singapore, July 19-23, 2010, IEEE.

Thilo Stadelmann, Yinghui Wang, Matthew Smith, Ralph Ewerth, and Bernd Freisleben. [**Rethinking Algorithm Development and Design in Speech Processing**](https://stdm.github.io/downloads/papers/ICPR_2010b.pdf). In Proceedings of the 20th International Conference on Pattern Recognition (**ICPR'10**), pages 4476-4479, Istanbul, Turkey, August 2010a. IAPR.

Thilo Stadelmann and Bernd Freisleben. [**Dimension-Decoupled Gaussian Mixture Model for Short Utterance Speaker Recognition**](https://stdm.github.io/downloads/papers/ICPR_2010a.pdf). In Proceedings of the 20th International Conference on Pattern Recognition (**ICPR'10**), pages 1602-1605, Istanbul, Turkey, August 2010a. IAPR.


#### 2009

Markus Mühling, Ralph Ewerth, Thilo Stadelmann, Bing Shi, and Bernd Freisleben. [**University of Marburg at TRECVID 2009: High-Level Feature Extraction**](https://stdm.github.io/downloads/papers/TRECVID_2009.pdf). In Proceedings of TREC Video Retrieval Evaluation Workshop (**TRECVid'09**).

Ernst Juhnke, Dominik Seiler, Thilo Stadelmann, Tim Dörnemann, and Bernd Freisleben. [**LCDL: An Extensible Framework for Wrapping Legacy Code**](https://stdm.github.io/downloads/papers/ERPAS_2009.pdf). In Proceedings of International Workshop on @WAS Emerging Research Projects, Applications and Services (**ERPAS'09**), pages 638-642, Kuala Lumpur, Malaysia, December 2009.

Dominik Seiler, Ralph Ewerth, Steffen Heinzl, Thilo Stadelmann, Markus Mühling, Bernd Freisleben, and Manfred Grauer. [**Eine Service-Orientierte Grid-Infrastruktur zur Unterstützung Medienwissenschaftlicher Filmanalyse**](https://stdm.github.io/downloads/papers/GeNeMe_2009.pdf). In Proceedings of the Workshop on Gemeinschaften in Neuen Medien (**GeNeMe'09**), pages 79-89, Dresden, Germany, September 2009.

Thilo Stadelmann and Bernd Freisleben. [**Unfolding Speaker Clustering Potential: A Biomimetic Approach**](https://stdm.github.io/downloads/papers/ACMMM_2009.pdf). In Proceedings of the ACM International Conference on Multimedia (**ACMMM'09**), pages 185-194, Beijing, China, October 2009. ACM.

Thilo Stadelmann, Steffen Heinzl, Markus Unterberger, and Bernd Freisleben. [**WebVoice: A Toolkit for Perceptual Insights into Speech Processing**](https://stdm.github.io/downloads/papers/CISP_2009.pdf). In Proceedings of the 2nd International Congress on Image and Signal Processing (**CISP'09**), pages 4358-4362, Tianjin, China, October 2009.

Steffen Heinzl, Markus Mathes, Thilo Stadelmann, Dominik Seiler, Marcel Diegelmann, Helmut Dohmann, and Bernd Freisleben. [**The Web Service Browser: Automatic Client Generation and Efficient Data Transfer for Web Services**](https://stdm.github.io/downloads/papers/ICWS_2009.pdf). In Proceedings of the 7th IEEE International Conference on Web Services (**ICWS'09**), pages 743-750, Los Angeles, CA, USA, July 2009. IEEE Press.

Steffen Heinzl, Dominik Seiler, Ernst Juhnke, Thilo Stadelmann, Ralph Ewerth, Manfred Grauer, and Bernd Freisleben. [**A Scalable Service-Oriented Architecture for Multimedia Analysis, Synthesis, and Consumption**](https://stdm.github.io/downloads/papers/IJWGS_2009.pdf). **International Journal of Web and Grid Services**, 5(3):219-260, 2009. Inderscience Publishers.


#### 2008

Markus Mühling, Ralph Ewerth, Thilo Stadelmann, Bing Shi, and Bernd Freisleben. [**University of Marburg at TRECVID 2008: High-Level Feature Extraction**](https://stdm.github.io/downloads/papers/TRECVID_2008.pdf). In Proceedings of TREC Video Retrieval Evaluation Workshop (**TRECVid'08**). 


#### 2007

Markus Mühling, Ralph Ewerth, Thilo Stadelmann, Bing Shi, Christian Zöfel, and Bernd Freisleben. [**University of Marburg at TRECVID 2007: Shot Boundary Detection and High-Level Feature Extraction**](https://stdm.github.io/downloads/papers/TRECVID_2007.pdf). In Proceedings of TREC Video Retrieval Evaluation Workshop (**TRECVid'07**).

Ralph Ewerth, Markus Mühling, Thilo Stadelmann, Julinda Gllavata, Manfred Grauer, and Bernd Freisleben. [**Videana: A Software Toolkit for Scientific Film Studies**](https://stdm.github.io/downloads/papers/DTiMS_2007.pdf). In Proceedings of the **International Workshop on Digital Tools in Film Studies '07**, pages 1-16, Siegen, Germany, 2007. Transcript Verlag.

Markus Mühling, Ralph Ewerth, Thilo Stadelmann, Bernd Freisleben, Rene Weber, and Klaus Mathiak. [**Semantic Video Analysis for Psychological Research on Violence in Computer Games**](https://stdm.github.io/downloads/papers/CIVR_2007.pdf). In Proceedings of the ACM International Conference on Image and Video Retrieval (**CIVR'07**), pages 611-618, Amsterdam, The Netherlands, July 2007. ACM.


#### 2006

Ralph Ewerth, Markus Mühling, Thilo Stadelmann, Ermir Qeli, Björn Agel, Dominik Seiler, and Bernd Freisleben. [**University of Marburg at TRECVID 2006: Shot Boundary Detection and Rushes Task Results**](https://stdm.github.io/downloads/papers/TRECVID_2006.pdf). In Proceedings of TREC Video Retrieval Evaluation Workshop (**TRECVid'06**).

Thilo Stadelmann and Bernd Freisleben. [**Fast and Robust Speaker Clustering Using the Earth Mover's Distance and MixMax Models**](https://stdm.github.io/downloads/papers/ICASSP_2006.pdf). In Proceedings of the 31st IEEE International Conference on Acoustics, Speech, and Signal Processing (**ICASSP'06**), volume 1, pages 989-992, Toulouse, France, April 2006. IEEE.


#### 2005 

Ralph Ewerth, Christian Behringer, Tobias Kopp, Michael Niebergall, Thilo Stadelmann, and Bernd Freisleben. [**University of Marburg at TRECVID 2005: Shot Boundary Detection and Camera Motion Estimation Results**](https://stdm.github.io/downloads/papers/TRECVID_2005.pdf). In Proceedings of TREC Video Retrieval Evaluation Workshop (**TRECVid'05**).


#### 2004

Thilo Stadelmann. [**Sprechererkennung in Videos**](https://stdm.github.io/downloads/papers/DiplomaThesis_2004.pdf). Diplomarbeit, **Fachhochschule Giessen-Friedberg**, 2004.
