---
title: Audio Processing @ ZHAW
layout: page
---

### Abstract

This page collects information and resources on audio processing research at ZHAW. If you are interested in (or need) audio processing research at/from ZHAW (as a colleague or pontential project partner), please contact us.

<span style="color: #ff0000;"><em><img class="size-full wp-image-135 aligncenter" alt="Sound_wave" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/Sound_wave.jpg" width="300" height="195" /></em></span>

### People

A group of scientists from different backgrounds is involved in audio processing research here at ZHAW (in alphabetical order):

<table>
  <tr>
    <td style="text-align: center;">
      <img class="alignnone size-thumbnail wp-image-143" alt="acke" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/acke-150x150.jpg" width="150" height="150" /><br /> <a href="www.zhaw.ch/=acke">Philipp Ackermann</a><br /> Digital mixing consoles<br /> Digital music<br /> Human computer interaction
    </td>
    
    <td style="text-align: center;">
      <img class="alignnone size-thumbnail wp-image-144" alt="ciel" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/ciel-150x150.jpg" width="150" height="150" /><br /> <a href="www.zhaw.ch/=ciel">Mark Cieliebak</a><br /> Mobile sound processing<br /> Natural language technologies
    </td>
  </tr>
  
  <tr>
    <td style="text-align: center;">
      <a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/dueo2.jpg"><img alt="dueo(2)" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/dueo2-140x150.jpg" width="140" height="150" /></a><br /> <a href="www.zhaw.ch/=dueo">Oliver Dürr</a><br /> Deep learning for sound & speech analysis
    </td>
    
    <td style="text-align: center;">
      <a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2015/09/hirc.jpg"><img class="alignnone size-thumbnail wp-image-286" alt="hirc" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2015/09/hirc-150x150.jpg" width="150" height="150" /><br /> </a><a href="www.zhaw.ch/=hirc">Sven Hirsch<br /> </a>Audio fingerprinting & music classification<br /> Sound installations
    </td>
  </tr>
  
  <tr>
    <td style="text-align: center;">
      <img alt="huhp" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/huhp-150x150.jpg" width="150" height="150" /><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=huhp" target="_blank"><br /> </a><a href="www.zhaw.ch/=huhp">Hans-Peter Hutter</a><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=huhp" target="_blank"><br /> </a>Automatic speech recognition<br /> Handset & channel normalization
    </td>
    
    <td style="text-align: center;">
      <a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/rosn.jpg"><img alt="rosn" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/rosn-150x150.jpg" width="150" height="150" /><br /> </a><a href="https://www.zhaw.ch/de/ueber-uns/person/rosn/" target="_blank">Matthias Rosenthal<br /> </a>3D audio algorithms<br /> Development of embedded hardware for signal processing
    </td>
  </tr>
  
  <tr>
    <td style="text-align: center;">
      <img alt="stdm" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/stdm-150x150.jpg" width="150" height="150" /><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=stdm" target="_blank"><br /> </a><a href="www.zhaw.ch/=stdm">Thilo Stadelmann</a><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=stdm" target="_blank"><br /> </a>Automatic speaker recognition & clustering (diarization)<br /> Music & multimedia information retrieval<br /> Sound classification and segmentation
    </td>
    
    <td style="text-align: center;">
      <a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/rosn.jpg"><img alt="wyrs" src="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/wyrs.jpg" width="100" height="128" /></a><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=wyrs" target="_blank"><br /> </a><a href="www.zhaw.ch/=wyrs">Sigisbert Wyrsch</a><a href="http://www.zhaw.ch/fileadmin/php_includes/popup/person-detail.php?kurzz=wyrs" target="_blank"><br /> </a>Active noise reduction /cancellation<br /> Digital audio signal processing<br /> Hearing aid engineering<a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2013/09/rosn.jpg"><br /> </a>
    </td>
  </tr>
</table>

<p style="text-align: center;">
  &#8230; to be continued (please get <a title="About" href="https://dublin.zhaw.ch/~stdm/?page_id=10" target="_blank">in touch</a>)!
</p>

### Projects

  * 2 Bachelor Theses (&#8220;BA&#8221;) and a graduate (PhD) project on &#8220;Machine Learning for Speaker Clustering&#8221; (FS 2017)
  * Hackathon (&#8220;M.Sc. EVA&#8221;) on &#8220;RNNs for Speaker Clustering&#8221; (HS 2016)
  * Project Thesis (&#8220;B.Sc. PA&#8221;) on &#8220;Recurrent Neural networks for Speaker Recognition&#8221; (HS 2016)
  * Paper at <a href="http://mlsp2016.conwiz.dk/home.htm" target="_blank">IEEE MLSP 2016</a> on <a href="https://www.zhaw.ch/no_cache/de/forschung/personen-publikationen-projekte/detailansicht-publikation/publikation/210537/" target="_blank">&#8220;Speaker Identification and Clustering using Convolutional Neural Networks&#8221;</a> (09/2016)
  
    _Deep learning, especially in the form of convolutional neural networks (CNNs),  has triggered substantial improvements in computer vision and related fields in recent years. This progress is attributed to the shift from designing features and subsequent individual sub-systems towards learning features and recognition systems end to end from nearly unprocessed data. For speaker clustering, however, it is still common to use handcrafted processing chains such as MFCC features and GMM-based models. In this paper, we use simple spectrograms as input to a CNN and study the optimal design of those networks for speaker identification and clustering. Furthermore, we elaborate on the question how to transfer a network, trained for speaker identification, to speaker clustering. We demonstrate our approach on the well known TIMIT dataset, achieving results comparable with the state of the art– without the need for handcrafted features._
  * CTI project 18338.1 PFEN-NM &#8220;Audio Processing in OpenCL&#8221; (March 2016 &#8211; October 2017)
  * Bachelor Thesis (&#8220;BA&#8221;) on &#8220;Instrument Recognition in Single-Source Audio Streams&#8221; (FS 2016)
  * Bachelor Thesis (&#8220;BA&#8221;) on &#8220;Automatic Voice Recognition with Deep Learning&#8221; (FS 2016)
  * Project Thesis (&#8220;B.Sc. PA&#8221;) on &#8220;Automatische Erkennung der Akkordfolge in Popmusik&#8221; (HS 2015)
  * Project Thesis (&#8220;B.Sc. PA&#8221;) on &#8220;Sprechererkennung mit Deep Neural Networks&#8221; (HS 2015)
  * Bachelor Thesis (&#8220;BA&#8221;) on &#8220;Deep Learning für automatische Stimmerkennung&#8221; (FS 2015)
  * Bachelor Thesis (&#8220;BA&#8221;) on &#8220;Entwicklung einer Android-App zur Erkennung von Redeanteilen im Unterricht&#8221; (FS 2015)
  * Bachelor Thesis (&#8220;BA&#8221;) on &#8220;Erkennung von Hintergrundmusik in Broadcast Audio&#8221; (FS 2015)
  * Project <a href="http://www.zhaw.ch/fileadmin/php_includes/popup/projekt-detail.php?projektnr=1799" target="_blank">Talkalyzer &#8211; Mobile App for Share-in-Speech Analysis via Real-Time Speaker Classification</a> (09/2013 &#8211; 12/2014)
  
    _The goal of this directly funded research project has been to develop a mobile application that is able to recognize the voice of the smartphone&#8217;s owner (and thus, his share in the current discussion in percent) during normal conversations. To this end, speaker recognition technologies had to be ported to the phone and customized to this challenging, unconstrained environment. The Talkalyzer project has so far spawned further research activities and 4 bachelor and 1 project thesis. A report on the results achieved so far is available <a href="https://dublin.zhaw.ch/~stdm/wp-content/uploads/2014/07/BA-Buch_Talkalyzer.pdf" target="_blank">here</a> (in German language)._

### Resources

  * <a href="http://www.web3.lu/spectrogram-speech-processing/" target="_blank">M. Barning, &#8220;Spectrograms and speech processing&#8221;, 2014</a>: Blog post on tools and background information on the spectrograms