---
title: Pro-human AI design - a primer
layout: post
date: 2025-12-04
modified: 2025-12-04
category: AI, society, hope, pro-human AI
comments: true
---

How can AI systems be designed to strengthen what makes us fully human, rather than undermining core aspects like relationality, responsibility and autonomy? "Pro-human AI tech design", or "pro-human AI" in short, is the field of study concerned with these questions. But why is it necessary in the first place?

![AI in 2035](http://stdm.github.io/images/pro-human-ai.jpg)

<!-- more -->


### Motivation

Recently, the New York Times published an [article](https://www.nytimes.com/2025/11/23/technology/openai-chatgpt-users-risks.html) detailing how design choices at OpenAI to enhance user engagement with their product ChatGPT lead to nearly 50 cases of psychosis: After conversing with the chat bot, nine users needed hospitalization and three died. The underlying issue was that the dialogue system had been designed to please humans by appearing supportive and understanding, making it too agreeable; the former "hacked" human users' natural drive to form relationships, and the latter supported, e.g., suicidal tendencies. 


### Background: Pro-social tech design for social media

These tragic incidents serve as a prime example for a major AI risk [^1], specifically of manipulating the human core [^2]: our fundamental properties that make us human and that we do not want to lose. Apparently, AI isn't just changing work but is changing us as it interacts with us on a deep level (in the example above: by using human language and appealing to affections, triggering attachment). In related circumstances, social media scholars have developed the field of "[pro-social tech design](https://www.techpolicy.press/toward-prosocial-tech-design-governance/)": principles and methods to analyze how a technological artefact interacts with society, measuring its impact, and designing for minimized negative influence.

Consider the "like"" button as an example: Created as a harmless device to boost user engagement [^3] by signaling support for posts, it has over the years changed our collective behavior as societies: the way we write to solicit likes; the way we strategically spend likes to boost agendas; etc. So much so that 15 years later we find society is split into neatly separated filter bubbles that can hardly stand talking to each other on major issues. Realizing the effect of the technology's design on that outcome, the researchers have suggested "pro-social" design methods to overcome respective problems (oversimplified: by, e.g., adding a button *"show me the common ground to my thinking"*). 


### From pro-social to pro-human AI: A method in the making

Seeing similar potential in the field of AI [^4], I assembled an interdisciplinary team to establish the methodological foundations for pro-human AI design: (a) compile what makes up the human at their core; (b) measure how a given AI system for a specific use case interacts with these core property; (c) and develop interventions to the system's design to mitigate any negative influence (if any). Amongst this prioneering group are Prof. [Christoph Heitz](https://www.zhaw.ch/en/about-us/person/heit) (AI fairness, ZHAW IDP), master's student [Rebekka von Wartburg](https://www.linkedin.com/in/rebekka-von-wartburg-kottler-3b807b298/), and several external advisors from the humanities, together with the company [Alpine AI](https://alpineai.swiss/en/) as use case provider. 

Our goal is to establish pro-human AI design methodologically by directly adressing all three steps (a)-(c) in the very first analysis that we are currently undertaking, as we believe that such approaches need to be anchored in practical use cases from the start. Preliminary results exist for step (a): What makes up the human?


#### The human core

This question is hard to answer once and for all, but after surveying the literature across psychology, anthropology, sociology, and theology, the following core properties appear to point in the direction of the sufficiently agreeable and complete [^5]: 

Humans are (-> a)
-	Relational and social: We cannot live in isolation, hence we seek connection to an other [^6].
-	Free and autonomous: We are fiercely independent; revoking a human's right to have any say in their own affairs (i.e., slavery) has been rightly abolished [^7].
-	Driven to shape: Everyone rules about their own circle of influence, exhibiting a drive to shape their environment [^8].
-	Embodied and limited: Arguably, we are not especially fond of most of the limitations of our mind and body, but as Neil Lawrence points out in "The Atomic Human", this is also what shapes our intelligence and humanity; becoming limitless hence is becoming less fully human, which is a qualitative regress [^9].
-	Transcendent: At the least, we all seek purpose and meaning [^10].

#### A product design methodology

Pro-human AI design then is the habit of taking into account, when designing any *specific AI system* for a *specific use case*, how this system interacts with each of these properties (-> b): Is any stakeholder's competency to exhibit one or more of these traits diminished profoundly by the AI system? For example, does work become meaningless? Is the user's ability to form meaningful human relationships or act socially reduced? Would their feeling of agency be weakened, the free forming of opinion manipulated? Then, countermeasures can be considered alongside other factors of product design (-> c).


### Join us!

We have started introducing colleagues in R&D as well as business leaders to the methodology of pro-human AI design [^11], and the [AI in 2035](https://stdm.github.io/AI-in-2035/) scenario published on this blog recently explores how pro-human AI design could profoundly influence a positive vision of our human future with AI. We see huge potential for this approach especially for the European economy and intend to develop it furether along reelvant business use cases. 

Please reach out if you want to collaborate with us on this.


## Footnotes

[^1]: In my recent [paper](https://doi.org/10.1080/09540962.2025.2541304) on AI risks, this one runs under the headline of "dependence".
[^2]: Neil Lawrence coined this term in the context of AI and how it relates to the human in his recent book [The Atomic Human](https://inverseprobability.com/atomic-human/).
[^3]: Mind the pattern: it was "engagement maximization" that also caused the harms reported by the New York Times [article](https://www.nytimes.com/2025/11/23/technology/openai-chatgpt-users-risks.html) above.
[^4]: While respective mechanisms of action appear very similar in both social media and AI (i.e., technology changing humans, not for the better), the target of the solution seems different to me: "Pro-social" tech design for social media aims foremost at a societal effect (countering increased anti-social behavior and the drifting apart of society). This is important and necessary. However, in AI, the first to suffer from any negative manipulation of the human core is the individual themselve. If otherwise the human flourishes, society benefits as well. Hence, in AI system design, I deem it important to aim first and foremost at improving things *for each individual human* (and societal effects will follow). Hence I opt for the term "pro-human" AI, although colleagues like [Conelia C. Walther](https://link.springer.com/article/10.1186/s44263-024-00111-z) work towards a similar direction under the term "pro-social AI".
[^5]: The list here is not sufficiently complete, but a first and quick summary. We intend to publish a more thorough analysis and reflections in the future.
[^6]: "*[T]he natural creaturely "person" came to be seen as not a social role but a concrete individual, who exercises his or her personhood in mutual relationships of self-gift that are self-expressive and other-receiving.*" ([Gunkel & Wales, 2021](https://link.springer.com/article/10.1007/s00146-020-01129-1)). "*[T]he need for affiliation and the need to matter positively to others are the specific features of human existence that are both derived from and contribute to the relationships that make human being human.*" ([Gastmans et al., 2024](https://onlinelibrary.wiley.com/doi/10.1111/bioe.13322)). "*A person's consciousness is more than what humans seem to share with gorillas; it is a consciousness that voluntarily reaches out to make contact with the consciousness of others as an act of self-giving; it is subjectivity oriented to inter-subjectivity. The mutual empathic compassion of our inter-subjectivity is more than inference concerning another's beliefs and desires; still less is it mere behavior-prediction. It is a voluntary coexperience as if of the other person's mind.*" (Gunkel & Wales, 2021). "*[P]ersons exist for relationships. Without relationships, creaturely persons would not cease to exist, but by refusing relationships of self-gift they would live as less than the persons they are.*" (Gunkel & Wales, 2021). "*We are shaped and motivated by community and by the stories, symbols, values, and practices we share with others, who, in turn, make us who we are.*" ([Segessenmann et al., 2025](https://link.springer.com/article/10.1007/s43681-023-00408-z)).
[^7]: "*Autonomy refers to the capacity to formulate norms, to reflect and to choose which norm to follow, thereby presupposing self-consciousness and freedom. Human agency is autonomous;*" (Gastmans et al., 2024).
[^8]: "*Responsibility is associated with autonomy, freedom and awareness of duties; as such, human beings are responsible. Moral responsibility in any sense cannot be allocated or shifted to 'autonomous' technology.*" (Gastmans et al., 2024). "*From developmental psychology, we learn that self-reflection and elationality should be viewed as fundamental human qualities. Humans ask themselves what and how they want to be and then act accordingly. [...] humans retain free will and a conscientious capacity that guides them to establish interpersonal relationships.*" (Gastmans et al., 2024).
[^9]: "*[H]uman being always and conjointly is a living body [Leib] [...] and has this living body as this physical thing [Koerper]*" ([Fuchs et al., 2024](https://www.mohrsiebeck.com/artikel/organisms-prostheses-and-the-limits-of-cyborgization-101628ptsc-2024-0016/)). "*The limits that define our nature, including the ultimate limitation of death, are essential to our humanness. To respect human dignity is to respect these limits. They are not to be overcome but taken as a site of moral reflection about what it means to live well as limited creatures of a certain sort.*" ([Calo, 2024](elgaronline.com/view/book/9781802205657/ch13.xml)).
[^10]: "*Understanding is a lifelong labor. It is also one carried out not by isolated individuals but by social beings who perform this cultural labor together and share its fruits. The labor of understanding is a sustained, social project, one that we pursue daily as we build, repair and strengthen the ever-shifting bonds of sense that anchor our thoughts to the countless beings, things, times and places that constitute a world. It is this labor that thinking belongs to.*" ([Vallor, 2024b](https://academic.oup.com/book/56292/chapter/445317996))
[^11]: For example, more than 1'500 business leaders have been introduced to this approach at various keynote speeches recently, e.g., at the [Swiss Insurance Award 2025](https://www.innovationspreis.hzinsurance.ch/), the [IPA Jahrestagung 2025](https://ipa-jahrestagung.de/events/ece6262c47), or the [FRZ Wirtschaftsforum 2025](https://www.persoenlich.com/marketing/wirtschaftsforum-mit-teilnehmerrekord). Additionally, [NZZ Jobs](https://jobs.nzz.ch/ratgeber/artikel/1204/prohumane-ki-wie-technologie-uns-staerkt-statt-uns-zu-schwachen) covered it in an interview (in German).